
import os
import json
import pickle
import scipy
import numpy as np
import pandas as pd
import scanpy as sc



# LOADING DATA


def load_starsolo(library_ids, input_path, filt_path='raw', load_USA='True'):

  '''
  Builds a library of AnnData objects from STARsolo output folders
  Expects both 'Gene' and 'Velocyto' outputs
  Loads each Velocyto/USA category into a separate adata layer
  Use filt_path to specify which version of the counts matrix will be loaded (e.g. 'raw')

  '''
  
  # Create a dictionary to hold data
  D = {}

  for s in library_ids:

    print('Loading '+s)

    # store "Gene" counts as X matrix  
    D[s] = sc.read_10x_mtx(input_path+s+'/Solo.out/Gene/'+filt_path+'/')
    D[s].obs['library_id'] = np.tile(s, [D[s].n_obs, 1])
    
    if load_USA:
        # store Unspliced, Spliced, and Ambiguous counts matrices (USA) each in their own layer
        D[s].layers['unspliced'] = sc.read_mtx(input_path+s+'/Solo.out/Velocyto/'+filt_path+'/unspliced.mtx.gz').X.transpose()
        D[s].layers['spliced'] = sc.read_mtx(input_path+s+'/Solo.out/Velocyto/'+filt_path+'/spliced.mtx.gz').X.transpose()
        D[s].layers['ambiguous'] = sc.read_mtx(input_path+s+'/Solo.out/Velocyto/'+filt_path+'/ambiguous.mtx.gz').X.transpose()

  return D 


def load_alevin(library_ids, input_path):
    '''
    Mirrors the functionality of load_inDrops
    Imports data files generated by Salmon-Alevin, when run with the --dumpMtx option. Specifically, this 
    function will expect files at the following locations:
    /input_path/library_id/alevin/quants_mat.mtx.gz
    /input_path/library_id/alevin/quants_mat_rows.txt
    /input_path/library_id/alevin/quants_mat_cols.txt
    where 'library_ids' contains one or more inDrops.py output folders located at the indicated path.
    '''
    
    # Create a dictionary to hold data
    D = {}
    for j, s in enumerate(library_ids):
        D[s] = {}

    # Load counts data, metadata, & convert to AnnData objects
    for s in library_ids:
        
        # Load counts, gene names into AnnData structure
        D[s] = sc.read_mtx(input_path + '/' + s + '/alevin/quants_mat.mtx.gz', dtype='float32')
        D[s].var_names = np.loadtxt(input_path + '/' + s + '/alevin/quants_mat_cols.txt', dtype='str')
        D[s].obs['library_id'] = np.tile(s, [D[s].n_obs, 1])
        D[s].uns['library_id'] = s

        # Load cell barcodes into AnnData structure
        cell_bcds = np.loadtxt(input_path + '/' + s + '/alevin/quants_mat_rows.txt', dtype='str')
        
        # Append library name to each cell barcode to create unique cell IDs
        lib_cell_bcds = []
        for bcd in cell_bcds:
            lib_cell_bcds.append(s + '_' + bcd)
        D[s].obs['unique_cell_id'] = lib_cell_bcds

    return D


def load_alevinfry(frydir, output_format="scRNA", nonzero=False, quiet=False):
    """
    This function is forked from: https://github.com/COMBINE-lab/pyroe
    Loads alevin-fry quantification results into an AnnData object
    Required Parameters
    ----------
    frydir : `str`
        The path to a output directory returned by alevin-fry quant command. \\
        The directory containing the alevin-fry quantification (i.e. the the quant.json file & alevin subdirectory).
    Optional Parameters
    ----------
    output_format : `str` or `dict`
        A string represents one of the pre-defined output formats, which are "scRNA", "snRNA" and "velocity". \\
        If a customized format of the returned `AnnData` is needed, one can pass a Dictionary.\\
        See Notes section for details.
    nonzero : `bool` (default: `False`)
        True if cells with non-zero expression value across all genes should be filtered in each layer.
        False if unexpressed genes should be kept.
    quiet : `bool` (default: `False`)
        True if function should be quiet.
        False if messages (including error messages) should be printed out.
    Notes
    ----------
    The `output_format` argument takes either a dictionary that defines the customized format or
    a string that represents one of the pre-defined format of the returned `AnnData` object.
    Each of the pre-defined formats contains a `X` field and some optional extra `AnnData.layers`
    obtained from the submatrices representing unspliced (U), spliced (S) and ambiguous (A) counts
    returned by alevin-fry.
    The following formats are defined:
    * "scRNA": \\
        This format is recommended for single cell RNA-sequencing experiments.
        It returns a `X` field that contains the S+A count of each gene in each cell without any extra layers.
    * "snRNA": \\
        This format is recommended for single nucleus RNA-sequencing experiments.
        It returns a `X` field that contains the U+S+A count of each gene in each cell without any extra layers.
    * "raw": \\
        This format uses the S count matrix as the `X` field and put the U, S, and A counts into three
        separate layers, which are "unspliced", "spliced" and "ambiguous".
    * "velocity": \\
        This format is the same as "scRNA", except it contains two extra layers: the "spliced" layer,
        which contains the S+A counts, and the "unspliced" layer, which contains the U counts.
    A custom output format can be defined using a Dictionary specifying the desired format of the output `Anndata` object.
    If the input is not a USA mode quantification directory, this parameter is ignored
    and the count matrix is returned in the `X` field of the returned `AnnData` object.  If the input
    quantification directory contains a USA mode quantification, then there are 3 sub-matrices that can
    be referenced in the dictionary; 'U', 'S', 'A' containing, respectively, unspliced, spliced and
    ambiguous counts.  The dictionary should have entries of the form `key` (str) : `value` (list[str]).
    The following constraints apply : there should be one key-value pair with the key `X`, the resulting
    counts will be returned in the `X` field of the AnnData object. There can be an arbitrary number
    of other key-value pairs, but each will be returned as a layer of the resulting AnnData object.
    Within the key-value pairs, the key refers to the layer name that will be given to the combined
    count matrix upon output, and the value should be a subset of `['U', 'S', 'A']` that defines
    which sub-matrices should be summed.  For example:
    `{'X' : ['S', 'A'], 'unspliced' : ['U']}`
    will result in a return AnnData object where the X field has a matrix in which each entry
    corresponds to the summed spliced and ambiguous counts for each gene in each cell, and there
    is an additional "unspliced" layer, whose counts are taken directly from the unspliced sub-matrix.
    Returns:
    ----------
        An AnnData object with X and layers corresponding to the requested `output_format`.
    """

    def process_output_format(output_format, quiet):
        # make sure output_format isn't empty
        if not output_format:
            raise ValueError("output_format cannot be empty")

        if isinstance(output_format, (str, dict)):
            if isinstance(output_format, str):
                predefined_format = {
                    "scrna": {"X": ["S", "A"]},
                    "snrna": {"X": ["U", "S", "A"]},
                    "velocity": {
                        "X": ["S", "A"],
                        "spliced": ["S", "A"],
                        "unspliced": ["U"],
                    },
                    "raw": {
                        "X": ["S"],
                        "spliced": ["S"],
                        "unspliced": ["U"],
                        "ambiguous": ["A"],
                    },
                }

                output_format = output_format.lower()
                if output_format not in predefined_format.keys():
                    # invalid output_format string
                    if not quiet:
                        print(
                            "Provided output_format string must be 'scRNA', 'snRNA', 'raw' or 'velocity'."
                        )
                        print("See function help message for details.")
                    raise ValueError("Invalid output_format.")
                if not quiet:
                    print("Using pre-defined output format:", output_format)
                    print(
                        f"Will populate output field X with sum of counts from {predefined_format[output_format]['X']}."
                    )
                    for (k, v) in predefined_format[output_format].items():
                        if k != "X":
                            print(f"Will combine {v} into output layer {k}.")

                return predefined_format[output_format]
            else:
                if not quiet:
                    print("Processing user-defined output format.")
                # make sure the X is there
                if "X" not in output_format.keys():
                    raise ValueError(
                        'In USA mode some sub-matrices must be assigned to the "X" (default) output.'
                    )
                if not quiet:
                    print(
                        f"Will populate output field X with sum of counts from {output_format['X']}."
                    )

                for (k, v) in output_format.items():
                    if not v:
                        # empty list
                        raise ValueError(
                            f"The element list of key '{k}' in output_format is empty. Please remove it."
                        )

                    # v contains Non-USA element
                    if len(set(v) - set(["U", "S", "A"])) != 0:
                        # invalid value
                        raise ValueError(
                            f"Found non-USA element in output_format element list '{v}' for key '{k}'; cannot proceed."
                        )
                    if not quiet and (k != "X"):
                        print(f"Will combine {v} into output layer {k}.")

                return output_format
        else:
            raise ValueError("Provided invalid output_format. See function help message for details")

    # since alevin-fry 0.4.1 the generic "meta_info.json"
    # has been replaced by a more informative name for each
    # sub-command. For quantification, it is "quant.json".
    # we check for both files here, in order.
    meta_info_files = ["quant.json", "meta_info.json"]

    fpath = os.path.sep.join([frydir, meta_info_files[0]])
    # first, check for the new file, if we don't find it, check
    # for the old one.
    if not os.path.exists(fpath):
        if not quiet:
            print(
                f"Did not find a {meta_info_files[0]} file, checking for older {meta_info_files[1]}."
            )
        fpath = os.path.sep.join([frydir, meta_info_files[1]])
        # if we don't find the old one either, then return None
        if not os.path.exists(fpath):
            raise IOError(f"Found no {meta_info_files[1]} file either; cannot proceed.")

    # if we got here then we had a valid json file, so
    # use it to get the number of genes, and if we are
    # in USA mode or not.
    meta_info = json.load(open(fpath))
    ng = meta_info["num_genes"]
    usa_mode = meta_info["usa_mode"]
    if not quiet:
        print(f"USA mode: {usa_mode}")

    # if we are in USA mode
    if usa_mode:
        # preparation
        # each gene has 3 splicing statuses, so the actual number of distinct
        # genes is ng/3.
        ng = int(ng / 3)
        output_assays = process_output_format(output_format, quiet)
    elif not quiet:
        print(
            "Processing input in standard mode, the count matrix will be stored in field 'X'."
        )
        if output_format != "scRNA":
            print("Output_format will be ignored.")

    # read the actual input matrix
    af_raw = sc.read_mtx(os.path.sep.join([frydir, "alevin", "quants_mat.mtx"]))
    afg = [
        line.rstrip()
        for line in open(
            os.path.sep.join([frydir, "alevin", "quants_mat_cols.txt"])
        ).readlines()
    ][:ng]
    # read the gene ids
    afg_df = pd.DataFrame(afg, columns=["gene_ids"])
    afg_df = afg_df.set_index("gene_ids")
    # and the barcodes
    abc = [
        line.rstrip()
        for line in open(
            os.path.sep.join([frydir, "alevin", "quants_mat_rows.txt"])
        ).readlines()
    ]
    abc_df = pd.DataFrame(abc, columns=["barcodes"])
    abc_df.index = abc_df["barcodes"]

    x = af_raw.X
    # if we're not in USA mode, just combine this info into
    # an AnnData object
    if not usa_mode:
        af = sc.AnnData(x.T, var=abc_df, obs=afg_df)
        af = af.T

    else:  # USA mode
        # otherwise, combine the sub-matrices into the output object as
        # specified by `output_assays`
        rd = {"S": range(0, ng), "U": range(ng, 2 * ng), "A": range(2 * ng, 3 * ng)}
        xcounts = output_assays["X"]
        o = x[:, rd[xcounts[0]]]
        for wc in xcounts[1:]:
            o += x[:, rd[wc]]
        af = sc.AnnData(o.T, var=abc_df, obs=afg_df)
        af = af.T

        # now, if there are other layers requested, populate those
        for other_layer in output_assays.keys() - "X":
            xcounts = output_assays[other_layer]
            o = x[:, rd[xcounts[0]]]
            for wc in xcounts[1:]:
                o += x[:, rd[wc]]
            af.layers[other_layer] = o

    if nonzero:
        not_zero_genes = af.X.sum(axis=0).A1 > 0
        if usa_mode:
            for other_layer in output_assays.keys() - "X":
                not_zero_genes = np.logical_or(
                    not_zero_genes, af.layers[other_layer].sum(axis=0).A1 > 0
                )

        af = af[:, not_zero_genes]

        if not quiet:
            print(f"Filtered {np.sum(~not_zero_genes)} non-expressed genes.")

    return af


def load_inDrops(library_ids, input_path):
    '''
    Imports data files generated by inDrops.py (https://github.com/indrops).  This function will expect
    files at the following locations:
    /input_path/library_id/library_id.counts.tsv.gz
    /input_path/library_id/abundant_barcodes.pickle
    where 'library_ids' contains one or more inDrops.py output folders located at the indicated path.
    
    The first time this function is executed, it will load counts matrices, gene names, cell names, and 
    cell barcode sequences from original tsv and pickle files, respectively.  Fast-loading versions of 
    these objects (e.g. *.npz) will be saved in place for future calls to this function.
    
    The returned dictionary object D with a ScanPy AnnData object for each library loaded, as follows:
    D[library_id] = AnnData object  
    Cell names and barcodes are stored in the adata.obs (cell barcodes as adata.obs['unique_cell_id'])
    Gene names are stored in adata.var
    Raw counts data are stored in adata.X
    This workflow allows each original library to be examined and pre-processed independently (e.g. barcode 
    filtering) prior to merging and further analysis.
    '''

    # Create a dictionary to hold data
    D = {}
    for j, s in enumerate(library_ids):
        D[s] = {}

    # Load counts data, metadata, & convert to AnnData objects
    for s in library_ids:
        print('_________________', s)

        # First attempt to load matrix data from preprocessed files (fast)
        if os.path.isfile(input_path + s + '/' + s + '.raw_counts.unfiltered.npz'):
            print('Loading from npz file')
            E = scipy.sparse.load_npz(
                input_path + s + '/' + s + '.raw_counts.unfiltered.npz')
            gene_names = np.loadtxt(
                fname=input_path + s + '/gene_names.txt', dtype='str')
            cell_names = np.loadtxt(
                fname=input_path + s + '/cell_names.txt', dtype='str')
            cell_bc_seqs = np.loadtxt(
                fname=input_path + s + '/cell_bc_seqs.txt', dtype='str')

        # Otherwise, load and preprocess from the original text files (slow)
        else:
            print('Loading from text file')
            counts_mat = pd.read_csv(
                input_path + s + '/' + s + '.counts.tsv.gz', sep='\t', index_col=0)
            E = scipy.sparse.coo_matrix(np.asmatrix(counts_mat.values)).tocsc()
            cell_names = counts_mat.index
            gene_names = counts_mat.columns

            # Load the barcode dictionary pickle file, format as keys=bcodes; values=sequences
            f = open(input_path + s + '/abundant_barcodes.pickle', 'rb')
            bc_dict = pickle.load(f)
            f.close()
            bcd_dict = {bc_dict[bc][0]: bc for bc in bc_dict}

            # Get barcode sequences corresponding to each cell index
            bcd_seqs = []
            for cname in counts_mat.index:
                bcd_seqs.append(s + '_' + bcd_dict.get(cname))
            cell_bc_seqs = bcd_seqs

            # Save fast files for next time
            scipy.sparse.save_npz(input_path + s + '/' +
                                  s + '.raw_counts.unfiltered.npz', E)
            np.savetxt(input_path + s + '/gene_names.txt',
                       counts_mat.columns, fmt='%s')
            np.savetxt(input_path + s + '/cell_names.txt',
                       counts_mat.index, fmt='%s')
            np.savetxt(input_path + s + '/cell_bc_seqs.txt',
                       bcd_seqs, fmt='%s')

        # Print matrix dimensions to screen
        print(E.shape, '\n')

        # Convert to ScanPy AnnData objects
        D[s] = sc.AnnData(E)
        D[s].var_names = gene_names
        D[s].obs['unique_cell_id'] = cell_bc_seqs
        D[s].obs['cell_names'] = cell_names
        D[s].obs['library_id'] = np.tile(s, [D[s].n_obs, 1])
        D[s].uns['library_id'] = s

    return D


load_inDrops_V3 = load_inDrops # alias to legacy function name 


def load_genedata(adata, csv_filename):
    '''
    Adds annotations to the 'var' dataframe of a ScanPy AnnData object (adata) from an imported CSV file.  
    Uses a set of unique identifiers (e.g. Ensembl gene IDs) to match genes.  These identifiers must be present 
    in AnnData (in adata.obs.var_names) and in the first column of the CSV file.
    
    The structure of the CSV file is as follows:
    Column 1: unique gene identifiers (exact string matches to elements of adata.var_names)
    Column 2: first gene annotation
    Column 3: second gene annotation
      ...          ....   
    Column n: last cell annotation  
    Column headers in the CSV file (required) will become headers of new columns in adata.var  
    Unique gene ids in adata that do not appear in the CSV file will be populated with the original unique ID.
    '''
    # load the unique gene IDs from adata that will be matched to the csv file
    uID_query = adata.var_names
    
    # load CSV header, get the names and number of IDs
    header = pd.read_csv(csv_filename, nrows=0)
    annotation_names = list(header.columns.values)[
        1:]  # ignore the first column header
    nAnnotations = len(annotation_names)
    
    # make a dictionary of unique gene IDs and annotations from the CSV file
    loadtxt = np.loadtxt(csv_filename, dtype='str', delimiter=',', skiprows=1)
    annotation_dict = {}
    for uID, *annots in loadtxt:   # column1 = uID, all remaining columns are annotations
        uID=uID.replace('-','')
        annotation_dict[uID] = annots
    
    # lookup each query in the dictionary, return matching annotations (or original uID)
    annotations = []
    for j, uID in enumerate(uID_query):
        if uID in annotation_dict:
            match = annotation_dict.get(uID)
            annotations.append(match)
        else:
            annotations.append(np.repeat(uID, nAnnotations).tolist())
    
    # convert from list of lists to array
    annotations = np.array(annotations)

    # now copy the matched annotations to adata
    for j in range(0, nAnnotations):
        adata.var[annotation_names[j]] = annotations[:, j]

    return adata


def load_celldata(adata, filepath, delim ='\t', filter_NA=False):
    '''
    Adds annotations to the 'obs' dataframe of an AnnData object from an imported metadata table  
    Uses a set of unique cell identifiers (e.g. cell barcode sequences) to match cells   
    Identifiers must be present in adata.obs_names
    The structure of the metadata file is as follows:
    Column 1: unique cell identifiers (exact string matches to elements of adata.obs_names)
    Column 2: first cell annotation
    Column 3: second cell annotation
      ...          ....   
    Column n: last cell annotation  
    Column headers in the metadata file (required) will become headers of new columns in adata.obs       
    Unique cell ids in adata that no not appear in the metadata file will be annotated as 'no match'.
    filter_NA gives an option to filter these cells from the outputted version of adata.
    '''
    
    # load the unique cell IDs from adata that will be matched to the csv file
    header = pd.read_table(filepath, nrows=0)
    annotation_names = list(header.columns.values)[1:]  # ignore the first column header
    nAnnotations = len(annotation_names)

    # make a dictionary of unique cell IDs and annotations from the tsv file
    loadtxt = np.loadtxt(filepath, dtype='str', delimiter=delim, skiprows=1)
    annotation_dict = {}
    for uID, *annots in loadtxt:   # column1 = uID, all remaining columns are annotations
        annotation_dict[uID] = annots

    # lookup each query in the dictionary, return matching annotations (or NaN if no match)
    annotations = []
    for j, uID in enumerate(adata.obs_names):
        if uID in annotation_dict:
            match = annotation_dict.get(uID)
            annotations.append(match)
        else:
            annotations.append(np.repeat(np.nan, nAnnotations).tolist())
    
    # convert to array and update adata.obs
    annotations = np.array(annotations)
    for j in range(0, nAnnotations):
        adata.obs[annotation_names[j]] = annotations[:, j]

    # if invoked, remove cells that were not present in the annotation CSV file
    if filter_NA:
        adata = adata[adata.obs[annotation_names[j]] != np.nan, :]

    return adata



